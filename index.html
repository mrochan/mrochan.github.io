<!doctype html>
<html>
<head>
<!-- Google Analytics 
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-111651742-1', 'auto');
ga('send', 'pageview');
</script>
 End Google Analytics -->

   <meta http-equiv="Content-Type" content="text/html; charset=utf-8" /> 
    <title>Home Page of Mrigank Rochan</title>
    <style>
    h1 { padding : 0; margin : 0; }
    body { padding : 20px 0; font-family : Arial; font-size : 16px; background-color:#c4d8e2; <!--background-image : url("images/bg2.png");--> } 
    #container { width : 900px; margin : 0 auto; background-color : #fff; padding : 50px;  text-align: left; box-shadow: 0px 0px 10px #999;; }
    #me { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0; margin-right:25px;}
    #content { display : block; margin-right : 0px;}
    a { text-decoration : none; }
    a:hover { text-decoration : underline; }
    a:link,a:visited
    {color: #1367a7;}    

    a.invisible { color : inherit; text-decoration : inherit; }
    .publogo { margin-top : 20px; margin-right : 10px; float : left; border : 0; width: 200px; vertical-align: middle;}
    
    .publication { clear : left; padding-bottom : 10px;}
    .codelogo { margin-right : 10px; float : left; border : 0;}
    .code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
    .code .download a { display : block; margin : 0 15px; float : left;}
    #simpsons { margin : 5px auto; text-align : center; color : #B7B7B7; }
    </style>

</head>
<body>
  <!-- #F2F2F2 -->
    <center>
    <div id="container">
    <img src="images/me_2.png" align = "right" width = 220 border="2">
    <div id="content">

    <h1>Mrigank Rochan</h1>
    <p>
    <a href="https://www.cs.usask.ca">Department of Computer Science</a><br>
    <a href="https://www.usask.ca">University of Saskatchewan</a><br>
	176 Thorvaldson Bldg<br>
    110 Science Place<br>
	Saskatoon, SK S7N 5C9, Canada<br>
    <br>
	<p>
    <a href="mailto: mrochan@cs.usask.ca" >Email</a> / <a href="https://scholar.google.com/citations?user=ALtJHVoAAAAJ&hl=en" >Google Scholar</a>
    </p>
    <br>
    <h2>About Me</h2>
   
    <p> I am an Assistant Professor in the Department of Computer Science at the <a href="https://www.cs.usask.ca/">University of Saskatchewan</a>. Previously, I was a Senior Researcher in the Autonomous Driving Perception team at Huawei Noah's Ark Lab, Canada. I received my Ph.D. and M.Sc. in Computer Science from the <a href="https://umanitoba.ca/" >University of Manitoba</a> in 2020 and 2016, respectively, where I was advised by Prof. <a href="https://users.encs.concordia.ca/~wayang/" >Yang Wang</a>. I obtained my B.Tech. degree in Computer Science and Engineering from <a href="http://www.amrita.edu" >Amrita University</a>, India, in 2011. I was a visiting research student at <a href="http://www.sfu.ca/computing.html" >Simon Fraser University</a> in 2015-2016. During my Ph.D., I also did a research internship at <a href="https://research.mapillary.com/" >Mapillary Research</a> (acquired by Meta). </p>
 
    <p>My research is focused on Deep Learning and its applications in Computer Vision. For my <a href="https://mspace.lib.umanitoba.ca/xmlui/handle/1993/34958" >thesis</a>, I received the <a href="https://www.cipprs.org/awards.html#doctoral">2020 CIPPRS John Barron Doctoral Dissertation Award</a>, a prestigious national award given annually by the Canadian Image Processing and Pattern Recognition Society (CIPPRS) to the top Ph.D. thesis in computer/robot vision.</p>

  <!-- <br> -->
  <center>
    <table border="0" cellpadding="0" cellspacing="0" width="900" align="center" bgcolor="#FFFFFF">   
     <!--
      <tr>
        <td width="20"></td>
            <td width="120" align="center" valign="middle"><a href="http://www.umanitoba.ca" ><img src="images/um_logo.png" height="70" /></a></td>
            <td width="120" align="center" valign="middle"><a href="https://research.mapillary.com/" ><img src="images/mapillary_research.png" height="45" /></a></td>
            <td width="120" align="center" valign="middle"><a href="http://www.sfu.ca" ><img src="images/sfu_logo.jpg" height="70" /></a></td>
            <td width="120" align="center" valign="middle"><a href="http://www.cognizant.com" ><img src="images/cognizant.png" height="85" /></a></td> 
            <td width="120" align="center" valign="middle"><a href="http://www.amrita.edu" ><img src="images/amrita_logo.png" height="85" /></a></td>
        <td width="40"></td>
      </tr> -->
      <!--
      <tr>
        <td width="20"></td>
            <td width="90" align="center" valign="middle">2016 - Present <br>2013 - 2016</br></td>
	    <td width="90" align="center" valign="middle">2018 - 2019</td>
            <td width="90" align="center" valign="middle">2015 - 2016</td>
	    <td width="70" align="center" valign="middle">2011 - 2013</td>
            <td width="70" align="center" valign="middle">2007 - 2011</td>
        <td width="40"></td>
      </tr>
      -->
  
  <tr>
  <td colspan = 7>
  <!--<p>&nbsp;</p>-->
    <h2>News</h2>
    <ul>
	<li><sup><font color="red"><b>NEW</b></font></sup> <b>10/2024</b>: One paper accepted to <a href="https://wacv2025.thecvf.com/">WACV 2025</a>!</li>   
	<li><sup><font color="red"><b>NEW</b></font></sup> <b>10/2024</b>: Two papers accepted to <a href="https://sslneurips2024.github.io/index.html">self-supervised learning</a> workshop at <a href="https://nips.cc/Conferences/2024">NeurIPS 2024</a>!</li>
    <li><sup><font color="red"><b>NEW</b></font></sup> <b>07/2024</b>: Received the <a href="https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/">Google PaliGemma</a> Academic Program Award!</li>
	<li><sup><font color="red"><b>NEW</b></font></sup> <b>06/2024</b>: Awarded the <a href="https://www.nserc-crsng.gc.ca/Professors-Professeurs/Grants-Subs/DGIGP-PSIGP_eng.asp">NSERC Discovery Grant</a>!</li>
	<li><sup><font color="red"><b>NEW</b></font></sup> <b>03/2024</b>: Two papers accepted to <a href="https://ieee-iv.org/2024/">IEEE IV 2024</a>!</li>
	<li><b>03/2023</b>: One paper accepted to <a href="https://2023.ieee-iv.org/">IEEE IV 2023</a>!</li>
    <li><b>03/2022</b>: One paper accepted to <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>!</li>
	<li><b>01/2022</b>: One paper accepted to <a href="https://www.icra2022.org/">ICRA 2022</a>!</li>
	<li><b>07/2021</b>: One paper accepted to <a href="http://iccv2021.thecvf.com/">ICCV 2021</a>!</li>
    <li><b>01/2021</b>: One paper accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE TPAMI</a>!</li>
    </ul>
  </td>
  </tr>

  <!-- Invited talks list -->
  <tr>
  <td colspan = 7>
    <h2>Invited Talks</h2>
    <ul>
	<li><sup><font color="red"><b>NEW</b></font></sup> <b>05/2025</b>: Invited symposium speaker at the <a href="https://www.computerrobotvision.org">Conference on Robots and Vision (CRV), 2025</a>!</li>
    <li><sup><font color="red"><b>NEW</b></font></sup> <b>10/2024</b>: Talk at <a href="https://research.adobe.com/careers/bangalore/">Adobe Research</a>!</li>
    <li><sup><font color="red"><b>NEW</b></font></sup> <b>10/2024</b>: Talk at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/">Microsoft Research</a>!</li>
    <li><b>12/2023</b>: Talk at <a href="https://research.google/teams/india-research-lab/">Google Research</a>!</li>
 	<li><b>12/2023</b>: <a href="https://cds.iisc.ac.in/events/seminar-cds-102-05th-december-advancing-visual-intelligence-innovations-across-images-videos-and-point-clouds/">Talk</a> at <a href="https://iisc.ac.in/">Indian Institute of Science (IISc)</a>, Bangalore!</li>
    </ul>
  </td>
  </tr>
 
  <!-- Teaching list -->
  <tr>
  <td colspan = 7>
     <h2>Teaching</h2>
     <ul>
  	 <li> CMPT 489/828: Deep Learning [Winter 2025, Winter 2024] </li>
	 <li> CMPT 318: Data Analytics [Winter 2025] </li>
     </ul>
  </td>
  </tr>

  <!-- Selected Research section starts here-->
  <tr>
  <td colspan = 7>
  <!--<p>&nbsp;</p> -->
  <br>
  <h2 style="display:inline;">Selected Publications</h2>
  <!--<div style="top:-10px; position:relative;">-->
  <table border="0" cellpadding="0" cellspacing="0" width="900" align="center" bgcolor="#FFFFFF">
 
  <tr>
    <td>
      <img border=0 src="images/wacv25_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Unsupervised Video Highlight Detection by Learning from Audio and Visual Recurrence</strong>
      <br>Zahidul Islam, Sujoy Paul, and <b>Mrigank Rochan</b>
      <br><em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<b>WACV</b>), 2025.
      <br><em>Workshop on Self-Supervised Learning, Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2024.
  <br><a href="https://openaccess.thecvf.com/content/WACV2025/papers/Islam_Unsupervised_Video_Highlight_Detection_by_Learning_from_Audio_and_Visual_WACV_2025_paper.pdf">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/ease25_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Large Language Models as Robust Data Generators in Software Analytics: Are We There Yet?</strong>
      <br>Md Awal, <b>Mrigank Rochan</b>, and Chanchal Roy
      <br><em>AI Models/Data track at the International Conference on Evaluation and Assessment in Software Engineering</em> (<b>EASE</b>), 2025.
      <br><a href="https://arxiv.org/abs/2411.10565">[arXiv]</a>
      </div>
    </td>
  </tr>
  
  <tr>
    <td>
      <img border=0 src="images/nips24w_highlighttta_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Test-Time Adaptation for Video Highlight Detection</strong>
      <br>Zahidul Islam, Sujoy Paul, and <b>Mrigank Rochan</b>
	  <br><em>Workshop on Self-Supervised Learning, Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2024.
      <br><a href="https://openreview.net/pdf?id=nzqmLjzaNt">[paper]</a>
      </div>
    </td>
  </tr>
  
  <!--
  <tr>
    <td>
      <img border=0 src="images/nips24w_unsuphighlight_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Leveraging Audio and Visual Recurrence for Unsupervised Video Highlight Detection</strong>
      <br>Zahidul Islam, Sujoy Paul, and <b>Mrigank Rochan</b>
	  <br><em>Workshop on Self-Supervised Learning, Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2024.
      <br><a href="https://openreview.net/pdf?id=obpHnDbjHU">[paper]</a>
      </div>
    </td>
  </tr>
  -->
  
  <tr>
    <td>
      <img border=0 src="images/iv24_gba_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Gradual Batch Alternation for Effective Domain Adaptation in LiDAR-Based 3D Object Detection</strong>
      <br><b>Mrigank Rochan</b>, Xingxin Chen, Alaap Grandhi, Eduardo Corral-Soto, and Bingbing Liu
      <br><em>IEEE Intelligent Vehicles Symposium</em> (<b>IV</b>), 2024.
      <br><a href="https://ieeexplore.ieee.org/document/10588523">[paper]</a>
      </div>
    </td>
  </tr>
 
  <tr>
    <td>
      <img border=0 src="images/iv24_density_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Effects of Range-based LiDAR Point Cloud Density Manipulation on 3D Object Detection</strong>
      <br>Eduardo Corral-Soto, Alaap Grandhi, Yannis He,<b> Mrigank Rochan</b>, and Bingbing Liu
      <br><em>IEEE Intelligent Vehicles Symposium</em> (<b>IV</b>), 2024.
      <br><a href="https://ieeexplore.ieee.org/document/10588517">[paper]</a>
      </div>
    </td>
  </tr>
 
  <tr>
    <td>
      <img border=0 src="images/iv23_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Domain Adaptation in LiDAR Semantic Segmentation via Hybrid Learning With Alternating Skip Connections</strong>
      <br>Eduardo Corral-Soto,<b> Mrigank Rochan</b>, Yannis He, Xingxin Chen, Shubhra Aich, and Bingbing Liu
      <br><em>IEEE Intelligent Vehicles Symposium</em> (<b>IV</b>), 2023.
      <br><a href="https://ieeexplore.ieee.org/abstract/document/10186529">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/cvpr22_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Contrastive Learning for Unsupervised Video Highlight Detection</strong>
      <br>Taivanbat Badamdorj,<b> Mrigank Rochan</b>, Yang Wang, and Li Cheng
      <br><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022.
      <br><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Badamdorj_Contrastive_Learning_for_Unsupervised_Video_Highlight_Detection_CVPR_2022_paper.pdf">[paper]</a>
      </div>
    </td>
  </tr>
  
  <tr>
    <td>
      <img border=0 src="images/icra22_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with Self-Supervision and Gated Adapters</strong>
      <br><b> Mrigank Rochan</b>, Shubhra Aich, Eduardo Corral-Soto, Amir Nabatchian, and Bingbing Liu
      <br><em>IEEE International Conference on Robotics and Automation</em> (<b>ICRA</b>), 2022.
      <br><a href="https://arxiv.org/abs/2107.09783">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/iccv21_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Joint Visual and Audio Learning for Video Highlight Detection</strong>
      <br>Taivanbat Badamdorj,<b> Mrigank Rochan</b>, Yang Wang, and Li Cheng
      <br><em>IEEE/CVF International Conference on Computer Vision</em> (<b>ICCV</b>), 2021.
      <br><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Badamdorj_Joint_Visual_and_Audio_Learning_for_Video_Highlight_Detection_ICCV_2021_paper.pdf">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/tpami21_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Referring Segmentation in Images and Videos with Cross-Modal Self-Attention Network</strong>
      <br>Linwei Ye,<b> Mrigank Rochan</b>, Zhi Liu, Xiaoqin Zhang, and Yang Wang
      <br><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<b>TPAMI</b>), 2021.
      <br><a href="https://arxiv.org/abs/2102.04762">[arXiv]</a> <a href="https://github.com/lwye/CMSA-Net">[code]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/tmm21_img.png" class="publogo" height="100">
    </td>
    <td>
      <div class="publication">
      <p><strong>AdaCrowd: Unlabeled Scene Adaptation for Crowd Counting</strong>
      <br>Mahesh Reddy, <b> Mrigank Rochan</b>, Yiwei Lu, and Yang Wang
      <br><em>IEEE Transactions on Multimedia</em> (<b>TMM</b>), 2021.
      <br><a href="https://arxiv.org/abs/2010.12141">[arXiv]</a> <a href="https://github.com/maheshkkumar/adacrowd">[code]</a>
      </div>
    </td>
  </tr>
 
  <tr>
    <td>
      <img border=0 src="images/phd_thesis_img.png" class="publogo" height="100" width="80">
    </td>
    <td>
      <div class="publication">
      <p><strong>Efficient Deep Learning Models for Video Abstraction</strong>
      <br><b> Mrigank Rochan</b>
      <br><em>Ph.D. Thesis, University of Manitoba,</em> 2020.
      <br><a href="https://www.cipprs.org/awards.html#doctoral" style="color:#FF0000;"><strong>CIPPRS John Barron Doctoral Dissertation Award</strong></a> <a href="https://youtu.be/4LiZtqaJQ5c?t=134">[announcement]</a>
      <br><a href="https://mspace.lib.umanitoba.ca/xmlui/handle/1993/34958">[link]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/eccv20_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Adaptive Video Highlight Detection by Learning from User History</strong>
      <br><b> Mrigank Rochan</b>, Mahesh Reddy, Linwei Ye, and Yang Wang
      <br><em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2020.
      <br><a href="https://arxiv.org/abs/2007.09598">[arXiv]</a> <a href="https://github.com/mrochan/adaptive-highlight">[code]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/bmvc20_img.png" class="publogo" height="110">
    </td>
    <td>
      <div class="publication">
      <p><strong>Sentence Guided Temporal Modulation for Dynamic Video Thumbnail Generation</strong>
      <br><b> Mrigank Rochan</b>, Mahesh Reddy, and Yang Wang
      <br><em>British Machine Vision Conference</em> (<b>BMVC</b>), 2020.
      <br><a href="https://arxiv.org/abs/2008.13362">[arXiv]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/wacv2020_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Few-Shot Scene Adaptive Crowd Counting Using Meta-Learning</strong>
      <br>Mahesh Reddy, Md Hossain, <b> Mrigank Rochan</b> and Yang Wang
      <br><em>IEEE Winter Conference of Applications on Computer Vision</em> (<b>WACV</b>), 2020.
      <br><a href="https://arxiv.org/abs/2002.00264">[arXiv]</a> <a href="https://github.com/maheshkkumar/fscc">[code]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/cvpr19_summary_img.jpg" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Video Summarization by Learning from Unpaired Data</strong>
      <br><b> Mrigank Rochan</b> and Yang Wang
      <br><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2019.
      <br><a href="https://arxiv.org/abs/1805.12174">[arXiv]</a>
      </div>
    </td>
  </tr>
  
  <tr>
    <td>
      <img border=0 src="images/cvpr19_refseg_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong>Cross-Modal Self-Attention Network for Referring Image Segmentation</strong>
      <br>Linwei Ye,<b> Mrigank Rochan</b>, Zhi Liu, and Yang Wang
      <br><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2019.
      <br><a href="https://arxiv.org/abs/1904.04745">[arXiv]</a> <a href="https://github.com/lwye/CMSA-Net">[code]</a>
      </div>
    </td>
  </tr>
  
   <tr>
    <td>
      <img border=0 src="images/icme19_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong> Convolutional Temporal Attention Model for Video-based Person Re-identification</strong>
      <br>Tanzila Rahman, <b> Mrigank Rochan</b>, and Yang Wang
      <br><em>IEEE International Conference on Multimedia and Expo</em> (<b>ICME</b>), 2019.
      <br><a href="https://arxiv.org/abs/1904.04492">[arXiv]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/eccv18_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong>Video Summarization Using Fully Convolutional Sequence Networks</strong>
      <br><b> Mrigank Rochan</b>, Linwei Ye, and Yang Wang
      <br><em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2018.
      <br><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Mrigank_Rochan_Video_Summarization_Using_ECCV_2018_paper.pdf">[paper]</a> <a href="https://arxiv.org/abs/1805.10538">[arXiv]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/bmvc18_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong> Future Semantic Segmentation with Convolutional LSTM</strong>
      <br>Shahab Nabavi, <b> Mrigank Rochan</b>, and Yang Wang
      <br><em>British Machine Vision Conference</em> (<b>BMVC</b>), 2018.
      <br><a href="https://arxiv.org/abs/1807.07946">[arXiv]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/cvpr17_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong> Gated Feedback Refinement Network for Dense Image Labeling</strong>
      <br>Md Amirul Islam, <b> Mrigank Rochan</b>, Neil Bruce, and Yang Wang
      <br><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2017.
      <br><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Islam_Gated_Feedback_Refinement_CVPR_2017_paper.pdf">[paper]</a> <a href="https://arxiv.org/abs/1806.11266">[extended version]</a> <a href="https://github.com/mrochan/gfrnet">[code]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/bmvc17_personid_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong> Person Re-Identification by Localizing Discriminative Regions</strong>
      <br>Tanzila Rahman, <b> Mrigank Rochan</b>, and Yang Wang
      <br><em>British Machine Vision Conference</em> (<b>BMVC</b>), 2017.
      <br><a href="http://www.bmva.org/bmvc/2017/papers/paper055/index.html">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/bmvc17_domain_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong> Adapting Object Detectors from Images to Weakly Labeled Videos</strong>
      <br> Omit Chanda, Eu Wern Teh, <b> Mrigank Rochan</b>, Zhenyu Guo, and Yang Wang
      <br><em>British Machine Vision Conference</em> (<b>BMVC</b>), 2017.
      <br><a href="http://www.bmva.org/bmvc/2017/papers/paper056/index.html">[paper]</a> <a href="https://github.com/omitum/adapt_yto">[code]</a>
      </div>
    </td>
  </tr>
  
  <tr>
    <td>
      <img border=0 src="images/bmvc17_saliency_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong> Salient Object Detection using a Context-Aware Refinement Network</strong>
      <br>Md Amirul Islam, Mahmoud Kalash, <b> Mrigank Rochan</b>, Neil Bruce, and Yang Wang
      <br><em>British Machine Vision Conference</em> (<b>BMVC</b>), 2017.
      <br><a href="http://www.bmva.org/bmvc/2017/papers/paper061/index.html">[paper]</a>
      </div>
    </td>
  </tr>
  
  
  <tr>
    <td>
      <img border=0 src="images/arxiv17_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong> Label Refinement Network for Coarse-to-Fine Semantic Segmentation</strong>
      <br>Md Amirul Islam, Shujon Naha, <b> Mrigank Rochan</b>, Neil Bruce, and Yang Wang
      <br><em>arXiv preprint arXiv:1606.07415</em>, 2017.
      <br><a href="https://arxiv.org/abs/1703.00551">[arXiv]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/bmvc16_img.png" class="publogo" height="130"></a>
    </td>
    <td>
      <div class="publication">
      <p><strong>Attention Networks for Weakly Supervised Object Localization</strong>
      <br>Eu Wern Teh, <b>Mrigank Rochan</b>, and Yang Wang
      <br><em>British Machine Vision Conference</em> (<b>BMVC</b>), 2016.
      <br><a href="http://www.bmva.org/bmvc/2016/papers/paper052/index.html">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/msc_thesis_img.png" class="publogo" height="80" width="80">
    </td>
    <td>
      <div class="publication">
      <p><strong>Object Localization in Weakly Labeled Images and Videos</strong>
      <br><b> Mrigank Rochan</b>
      <br><em>M.Sc. Thesis, University of Manitoba,</em> 2016.
      <br><a href="https://mspace.lib.umanitoba.ca/xmlui/handle/1993/31811">[link]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/ivc16_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong>Weakly Supervised Object Localization and Segmentation in Videos</strong>
      <br><b>Mrigank Rochan</b> and Yang Wang
      <br><em>Image and Vision Computing</em> (<b>IVC</b>), 2016.
      <br><a href="http://www.cs.umanitoba.ca/~ywang/papers/ivc16.pdf">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/cvpr15_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong>Weakly Supervised Localization of Novel Objects using Appearance Transfer</strong>
      <br><b>Mrigank Rochan</b> and Yang Wang
      <br><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2015.
      <br><a href="https://openaccess.thecvf.com/content_cvpr_2015/papers/Rochan_Weakly_Supervised_Localization_2015_CVPR_paper.pdf">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/crv15_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong>Latent SVM for Object Localization in Weakly Labeled Videos</strong>
      <br><b>Mrigank Rochan</b> and Yang Wang
      <br><em>Canadian Conference on Computer and Robot Vision</em> (<b>CRV</b>), 2015.
      <br><a href="http://www.cs.umanitoba.ca/~ywang/papers/crv15_lsvm.pdf">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/isvc14_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong>Efficient Object Localization and Segmentation in Weakly Labeled Videos</strong>
      <br><b>Mrigank Rochan</b> and Yang Wang
      <br><em>International Symposium on Visual Computing</em> (<b>ISVC</b>), 2014.
      <br><b>Oral Presentation</b>
      <br><a href="http://www.cs.umanitoba.ca/~ywang/papers/isvc14_weakly.pdf">[paper]</a>
      </div>
    </td>
  </tr>

  <tr>
    <td>
      <img border=0 src="images/crv14_img.png" class="publogo" height="130">
    </td>
    <td>
      <div class="publication">
      <p><strong>Segmenting Objects in Weakly Labeled Videos</strong>
      <br><b>Mrigank Rochan</b>, Shafin Rahman, Neil Bruce, and Yang Wang
      <br><em>Canadian Conference on Computer and Robot Vision</em> (<b>CRV</b>), 2014.
      <br><b>Oral Presentation</b>
      <br><a href="http://www.cs.umanitoba.ca/~ywang/papers/crv14.pdf">[paper]</a> <a href="https://www.youtube.com/watch?v=BcLGG9AIs7Y">[demo video]</a>
      </div>
    </td>
  </tr> 

  <tr>
    <td>
      <img border=0 src="images/icip14_img.png" class="publogo" height="120">
    </td>
    <td>
      <div class="publication">
      <p><strong> Examining Visual Saliency Prediction in Naturalistic Scenes</strong>
      <br>Shafin Rahman, <b>Mrigank Rochan</b>, Yang Wang, and Neil Bruce
      <br><em>IEEE International Conference on Image Processing</em> (<b>ICIP</b>), 2014.
      <br><b>Oral Presentation</b>
      <!-- Use target="_new"OR"_blank" to open link in new tab-->
      <!--<br><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7025829" target="_new">[paper]</a> -->
      <br><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7025829">[paper]</a> 
      </div>
    </td>
  </tr>
  
  <tr>
    <td></td>
    <td><br><strong><a href="https://scholar.google.com/citations?user=ALtJHVoAAAAJ&hl=en">See Google Scholar for full publication list</a></td>
    <td></td>
  </tr>    

  </table>
  </td>
  </tr>
  <!-- Selected Research section ends here-->

  <!--
  <tr>
  <td colspan = 7>
  <p>&nbsp;</p>
    <h2>Theses</h2>
    <ul>
	<li><a href="http://hdl.handle.net/1993/34958"><strong>Efficient Deep Learning Models for Video Abstraction</strong></a>, Mrigank Rochan, Ph.D. Thesis, University of Manitoba, 2020. <a href="https://www.cipprs.org/awards.html#doctoral" style="color:#FF0000;"><strong>CIPPRS John Barron Doctoral Dissertation Award 2020</strong></li>
	<li><a href="http://hdl.handle.net/1993/31811"><strong>Object Localization in Weakly Labeled Images and Videos</strong></a>, Mrigank Rochan, M.Sc. Thesis, University of Manitoba, 2016.</li>
    </ul>
  </td>
  </tr>
  -->

</table>
</center>
</div>
</div>
</center>

<table border="0" cellpadding="0" cellspacing="0" width="900" align="center">
  <tr>
    <td width="50" height="44" align = "right"><p><font size="2px"> <a href="http://people.csail.mit.edu/weichium/">Imitation is the sincerest form of flattery!</a> </font></p></td>
  </tr>
</table>

</body>
</html>
